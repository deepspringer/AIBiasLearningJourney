export const ALGORITHMIC_BIAS_TEXT = [
  "Algorithmic bias refers to systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one arbitrary group of users over others. Bias can emerge from many factors, including but not limited to the design of the algorithm or the unintended or unanticipated use or decisions relating to the way data is coded, collected, selected, or used to train the algorithm.",
  "Machine learning algorithms learn to make decisions based on training data, which can include biased human decisions or reflect historical or social inequities, even if sensitive variables such as gender, race, or sexual orientation are removed. This is known as \"bias in, bias out\" - when algorithms are trained on data containing human biases, they can amplify those biases in their outputs.",
  "For example, an AI hiring tool trained on historical hiring data might learn to prefer male candidates for technical roles if that reflects past hiring patterns. Similarly, facial recognition systems may perform better on lighter-skinned faces if they were primarily trained on datasets with underrepresentation of darker-skinned individuals.",
  "Addressing algorithmic bias requires diverse datasets, regular auditing for fairness, transparent AI systems, and diverse teams developing these technologies. Some researchers advocate for \"algorithmic fairness\" - designing systems that produce fair and equitable outcomes across different demographic groups.",
  "As AI systems become more integrated into society, understanding and mitigating algorithmic bias is crucial. Researchers, companies, and policymakers are increasingly working on methods to detect and reduce bias in algorithms to ensure these technologies benefit everyone fairly."
];
